{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5240784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'Ġhow', 'Ġare', 'Ġyou', '?']\n",
      "{'input_ids': tensor([[9707,   11, 1246,  525,  498,   30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\")\n",
    "\n",
    "qwen2_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "mytext = \"Hello, how are you?\"\n",
    "tokens = tokenizer.tokenize(mytext)\n",
    "print(tokens)\n",
    "\n",
    "tokens_qwen2 = qwen2_tokenizer(mytext, return_tensors=\"pt\")\n",
    "print(tokens_qwen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25346198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "qwebn2_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "\n",
    "qwen3_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-4B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d1ff15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwebn2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578c635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor type unknown to einops <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformer_lens\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HookedTransformer\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mHookedTransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQwen/Qwen3-4B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/Qwen3TransformerLens/transformer_lens/HookedTransformer.py:1359\u001b[39m, in \u001b[36mHookedTransformer.from_pretrained\u001b[39m\u001b[34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001b[39m\n\u001b[32m   1355\u001b[39m     center_unembed = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1357\u001b[39m \u001b[38;5;66;03m# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to\u001b[39;00m\n\u001b[32m   1358\u001b[39m \u001b[38;5;66;03m# match the HookedTransformer parameter names.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1359\u001b[39m state_dict = \u001b[43mloading\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_pretrained_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mofficial_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfrom_pretrained_kwargs\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[38;5;66;03m# Create the HookedTransformer object\u001b[39;00m\n\u001b[32m   1364\u001b[39m model = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m   1365\u001b[39m     cfg,\n\u001b[32m   1366\u001b[39m     tokenizer,\n\u001b[32m   1367\u001b[39m     move_to_device=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1368\u001b[39m     default_padding_side=default_padding_side,\n\u001b[32m   1369\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/Qwen3TransformerLens/transformer_lens/loading_from_pretrained.py:1931\u001b[39m, in \u001b[36mget_pretrained_state_dict\u001b[39m\u001b[34m(official_model_name, cfg, hf_model, dtype, **kwargs)\u001b[39m\n\u001b[32m   1929\u001b[39m     state_dict = convert_qwen_weights(hf_model, cfg)\n\u001b[32m   1930\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m cfg.original_architecture == \u001b[33m\"\u001b[39m\u001b[33mQwen2ForCausalLM\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m cfg.original_architecture == \u001b[33m\"\u001b[39m\u001b[33mQwen3ForCausalLM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1931\u001b[39m     state_dict = \u001b[43mconvert_qwen2_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m cfg.original_architecture == \u001b[33m\"\u001b[39m\u001b[33mPhiForCausalLM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1933\u001b[39m     state_dict = convert_phi_weights(hf_model, cfg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research/Qwen3TransformerLens/transformer_lens/pretrained/weight_conversions/qwen2.py:32\u001b[39m, in \u001b[36mconvert_qwen2_weights\u001b[39m\u001b[34m(qwen, cfg)\u001b[39m\n\u001b[32m     29\u001b[39m state_dict[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.attn._W_V\u001b[39m\u001b[33m\"\u001b[39m] = W_V\n\u001b[32m     31\u001b[39m b_Q = qwen.model.layers[l].self_attn.q_proj.bias\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m b_Q = \u001b[43meinops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb_Q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m(n_head d_head) -> n_head d_head\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_head\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m b_K = qwen.model.layers[l].self_attn.k_proj.bias\n\u001b[32m     39\u001b[39m b_K = einops.rearrange(\n\u001b[32m     40\u001b[39m     b_K,\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m(n_head d_head) -> n_head d_head\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     n_head=cfg.n_key_value_heads,\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen3_test/lib/python3.11/site-packages/einops/einops.py:600\u001b[39m, in \u001b[36mrearrange\u001b[39m\u001b[34m(tensor, pattern, **axes_lengths)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, **axes_lengths: Size) -> Tensor:\n\u001b[32m    546\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[33;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[33;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m \n\u001b[32m    599\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrearrange\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen3_test/lib/python3.11/site-packages/einops/einops.py:527\u001b[39m, in \u001b[36mreduce\u001b[39m\u001b[34m(tensor, pattern, reduction, **axes_lengths)\u001b[39m\n\u001b[32m    525\u001b[39m     tensor = backend.stack_on_zeroth_dimension(tensor)\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     backend = \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m hashable_axes_lengths = \u001b[38;5;28mtuple\u001b[39m(axes_lengths.items())\n\u001b[32m    530\u001b[39m shape = backend.shape(tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen3_test/lib/python3.11/site-packages/einops/_backends.py:59\u001b[39m, in \u001b[36mget_backend\u001b[39m\u001b[34m(tensor)\u001b[39m\n\u001b[32m     56\u001b[39m                 _type2backend[_type] = backend\n\u001b[32m     57\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor type unknown to einops \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(tensor)))\n",
      "\u001b[31mRuntimeError\u001b[39m: Tensor type unknown to einops <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "model = HookedTransformer.from_pretrained(\"Qwen/Qwen3-4B\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320078d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM \n",
    "\n",
    "\n",
    "\n",
    "qwen3 = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-4B\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1899da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c772fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
